## 目录
| 主要内容 | 地址 |
| -------- | ---- |
| 多模态机器学习简介 |      |
| 研究进展 |      |


## 多模态机器学习MultiModal Machine Learning
(2017)文献：[Multimodal Machine Learning: A Survey and Taxonomy](https://arxiv.org/abs/1705.09406)

### 定义
**模态**Modality: 事物存在的某些特定方式，如一只动物的外形、声音、气味和皮肤纹理等都可称为模态，**模态都是异质性的**。
**多模态**Multimodal: 多模态，也就是同时具有多个模态。一个研究问题或者数据集可以同时包含一个目标的多种类型数据，这可以被称为多模态。

### 目的和目标：
* 为了使人工智能进一步加强对我们周边事物的理解，它需要**具备解释多模态信号的能力**。（因为我们就身处在一个多模态的环境中，接收并处理着大量多模态信号）
* 多模态机器学习致力于搭建**能够处理和连接多模态信息的模型**

### 面临的挑战Challenge：
#### 表征（_Representation_）
1. 表征也可以理解为表示，即试图通过各模态的信息找到某种对多模态信息的统一表示。一般都会是一个向量，但维度、各维度的具体值能否具备好的性质就成了关键。那么什么是好的性质呢？这需要具体任务具体分析，一个简单的例子，如果做的是多模态信息检索（就是比如百度搜索“在捉老鼠的猫”，能得到一系列图片和视频），学习出的视频、图片、文本的表征（向量）的相似性非常重要，**来自同一个体的不同模态信息的表征（向量）间应具备更高的相似程度**。
2. 表征是一个非常基础的任务，好的表征能极大的提高模型的表现
3. 表征问题的**困难点**：
    - **如何结合异质性来源的数据**-文字、图片、视频、声音等
    - **如何处理不同模态的噪音**，因为不同模态的噪音是不同的
    - **如何处理数据缺失问题**
4. 好的表征方式：    
	- **平滑**映射
	- **时序和空间的一致性**
	- **稀疏性**
	- **自然聚类**
	- **在表征空间的相似性能够翻译出表征所对应的概念的相似性**
	- **即使在某些模态数据缺失的情况下，这些表征依旧能够轻松获得**
	- 能够**在给出被观察到的其它模态的数据后，填补缺失的模态数据**
1. 主要使用的表征思路：
    -   **Joint Representation**连接表示：神经网络；图模型；序列 
    -   **Coordinated Representation**相关性表示：相似性；结构化

#### 翻译（_Translation_）
1. 翻译的过程可以理解为映射，MMML很大一部分研究专注于**将一种模态数据翻译成另一种模态的数据**。也就是给定实体的一个模态，需要生成该实体的另一个模态。例如给出一段人说话的脸部特写视频，需要生成人说话的声音信号。
2. 基本技术分类：
    - Example-based字典查询映射
    - Generative生成式自动探索
1. 困难点：**非常难于评估**，因为这类任务没有标准答案
2. 为了解决评估困难，提出了VQA（Visual question-answering）任务。然而它也有问题，例如特定问题的歧义性，回答和问题偏置(ambiguity of certain questions and answers and question bias)

#### 对齐（_Alignment_）
1. 从两个甚至多个模态中寻找事物子成份之间的关系和联系
2. 对齐分为两类：**显式对齐和隐式对齐**。显式对齐即应用的主要任务就是对齐，而隐式对齐是指应用在完成主要任务时需要用到对齐的技术
3.  显式对齐的技术方法分类
    - 无监督方法 **Unsupervised**
    - (弱)监督方法 **(Weakly)Supervised**
4.  隐式对齐的技术方法分类
    - 图模型 **Graphical models**
    - 神经网络 **Neural networks** ----- 综述中尤其提到attention机制
5. 对齐任务的困难点
	 - 很少有显式对齐标注的数据集
	 - 很难建模不同模态之间相似度计算
	 - 存在多个可能的对齐方案，并且不是一个模态的所有元素都能在另一个模态中对应找到
#### 融合（_Fusion_）
融合是MMML最早的关注点之一
1. 多模态融合指**从多个模态信息中整合信息来完成分类或回归任务**。融合还有更宽泛的定义，而综述中的定义的融合，是指任务在最后预测并以预测输出值为目的时才进行多模态整合。在深度神经网络方法下，融合和表征两个任务是很难区分的。但在图模型以及基于核的方法中比较好区分。
2. 融合的价值：
	 - **在观察同一个现象时引入多个模态，可能带来更健壮(robust)的预测**
	 - 接触多个模态的信息，可能让我们**捕捉到互补的信息**（complementary information），尤其是这些信息在单模态下并不“可见”时
	 - **一个多模态系统在缺失某一个模态时依旧能工作**
3. 多模态融合有两大类：
	 - 无模型 **model-agnostic**
	 - 基于模型 **model-based**
4. 不直接依赖于某个特定的机器学习算法—分类为**early\late\hybrid fusion**
	 - **Early Fusion，也叫Feature-Based(基于特征)的模态融合**，通常是**在各模态特征被抽取后就进行融合**，通常只是简单的连接他们的表征(也就是joint representation)，直接连接多个向量。并使用融合后的数据进行模型训练，相比之后两种在训练上更为简单。
	 - **Late Fusion**，也称为Decision-based(基于决策)的模态融合，在各个模态做出决策后才进行融合，得出最终的决策。常见的机制有平均（averaging）、投票（voting schemes）等等。这种方法中，各模态可以使用不同的模型来训练，带来更多的便利性。
	 - **Hybrid Fusion**，混合融合方式，一种尝试结合early fusion和late fusion优势的方法。
5. 依赖于某个机器学习方法的融合方法，以显式的方法完成模态融合
	 - **Multiple Kernel learning(MKL)**，多核学习
	 - **Graphical models**，图模型
	 - **Neural Networks**，神经网络
	 - 神经网络在近期成为解决融合问题非常流行的方案，然而图模型以及多核学习依旧被使用，尤其是在有限的训练数据和模型可解释性非常重要的情况下。
6. 融合任务的困难点：
	 - 信号可能并不是时序对齐的（temporally aligned）。很可能是密集的连续信号和稀疏的事件（比如一大段视频只对应一个词，然后整个视频只对应稀少的几个词）
	 - 很难构建那些补全互补性信息的模型
#### 联合学习（_Co-learning_）
1. 联合学习的目的是通过利用资源丰富（比如数据量大）的模态的知识来辅助资源稀缺（比如较小数据）的模态建立模型
2. 联合学习时任务独立的（task independent）并可以用于提升融合、翻译和对齐任务中的模型
3. 联合学习中，辅助模态（helper modality）通常只参与模型的训练过程，并不参与模型的测试使用过程。即使用时，模型输入并不需要辅助模态的数据
4. 联合学习的分类是基于训练资源（数据）形式划分的，下图的文字部分解释得很清楚，并在分类后记录各分类涉及的技术：
	 - Parallel：协同训练/成对数据训练方法
	 - Non-Parallel：概念训练方法/非协同训练法
	 - Hyvrid：桥接方法


